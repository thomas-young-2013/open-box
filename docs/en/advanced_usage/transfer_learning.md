# Transfer Learning

When performing BBO, users often run tasks that are similar to
previous ones. This observation can be used to speed up the current task.
Compared with Vizier, which only provides limited transfer learning
functionality for single-objective BBO problems, OpenBox employs
a general transfer learning framework with the following
advantages:

1) Support for generalized black-box optimization problems;

2) Compatibility with most Bayesian optimization methods.

OpenBox takes as input observations from ğ¾ + 1 tasks: D<sup>1</sup>, ...,
D<sup>ğ¾</sup> for ğ¾ previous tasks and D<sup>ğ‘‡</sup> for the current task. 
Each D<sup>ğ‘–</sup> = {(ğ’™, ğ’š)},
ğ‘– = 1, ...,ğ¾, includes a set of observations. Note that,
ğ’š is an array, including multiple objectives for configuration ğ’™.
For multi-objective problems with ğ‘ objectives, we propose to
transfer the knowledge about ğ‘ objectives individually. Thus, the
transfer learning of multiple objectives is turned into ğ‘ single-objective
transfer learning processes. For each dimension of the
objectives, we take the following transfer-learning technique:

1) We first train a surrogate model ğ‘€<sup>ğ‘–</sup> on ğ·<sup>ğ‘–</sup> for the ğ‘–-th prior task
and ğ‘€<sup>ğ‘‡</sup> on ğ·<sup>ğ‘‡</sup>; 

2) Based on ğ‘€<sup>1:ğ¾</sup> and ğ‘€<sup>ğ‘‡</sup>, we then build a transfer learning surrogate by combining all base surrogates:
ğ‘€<sup>TL</sup> = agg({ğ‘€<sup>1</sup>, ...,ğ‘€<sup>ğ¾</sup>,ğ‘€<sup>ğ‘‡</sup> };w);

3) The surrogate ğ‘€<sup>TL</sup> is used to guide the configuration search,
instead of the original ğ‘€<sup>ğ‘‡</sup>. 

Concretely, we use gPoE to combine the multiple base surrogates (agg), 
and the parameters w are calculated based on the ranking of configurations, 
which reflects the similarity between the source tasks and the target task.


## Performance Comparison
We compare OpenBox with a competitive transfer learning baseline Vizier and a non-transfer baseline SMAC3. 
The average performance rank (the lower, the better) of each algorithm is shown in the following figure. 
For experimental setups, dataset information and more experimental results, please refer to our [published article]().


<p align="center">
<img src="https://raw.githubusercontent.com/thomas-young-2013/open-box/master/docs/imgs/tl_lightgbm_75_rank_result.svg" width="70%">
</p>

+ Average rank of tuning LightGBM with transfer learning
